{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c416e1-5d5a-45f2-826b-05ba2378077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59bb99-c3b8-49fa-bd59-4f09f4e1d460",
   "metadata": {},
   "source": [
    "***\n",
    "인공 신경망 (Artifitial Neural Network, ANN)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241674e-c796-4a1f-afc3-124a277dd16c",
   "metadata": {},
   "source": [
    "다층 퍼셉트론은 이름 그대로 퍼셉트론의 층이 여러개라는 뜻으로 다층 퍼셉트론은 기존의 데이터 공간을 변형함으로써  \n",
    "기존 하나의 퍼셉트론으로 해결할 수 없었던 문제를 해결할 수 있게 되는 것이다.  \n",
    "이처럼 다수의 뉴런을 사용해서 만든 것을 인공 신경망이라고 하며 줄여서 신경망이라 부른다.\n",
    "\n",
    "<img src=\"인공신경망 (1).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d871a5-65dd-4714-8bca-9bdd42119b8b",
   "metadata": {},
   "source": [
    "입력층(input Layer)에 입력된 데이터는 출력층(Output Layer)에 도달하기 전에 은닉층(Hidden Layer)이라는 층을 거친 후 출력층에 도달한다.  \n",
    "은닉층은 하나의 층뿐만 아니라 다수의 층으로 정할 수 있고 딥러닝이라는 이름은 이 은닉층의 깊이가 깊다는 뜻(함수가 깊게 중첩된다.)에서 나온 이름이다.  \n",
    "입력층의 노드 갯수는 피쳐 갯수와 동일하고 출력층의 노드 갯수는 분류하려는 클래스 갯수와 같다.  \n",
    "\n",
    "출력층의 각 노드가 나타내는 해당 클래스에 대한 점수이며 점수가 높을수록 해당 클래스에 속할 확률이 높다는 의미이고,  \n",
    "최종적으로 점수가 가장 높은 클래스를 선정한다.\n",
    "\n",
    "신경망 함수는 $f(x) = f_3(f_2(f_1(x)))$와 같은 합성 함수 형태로 표현된다. $f_1$을 첫번째 신경망 층, $f_2$을 두번째 신경망 층, $f_3$을 세번째 신경망 층이라고 생각하면 된다.  \n",
    "신경망 층이 깊을수록 함수의 갯수는 많아지고, 합성함수도 복잡해진다.  \n",
    "이때, 합성함수의 갯수는 모델의 깊이(depth)를 의미하는데, 딥러닝에서 Deep이라는 용어가 바로 여기에서 나온 용어이다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085be4f-37c2-438b-adc7-baef8127906a",
   "metadata": {},
   "source": [
    "***\n",
    "오차 역전파(Back Propagation)\n",
    "***\n",
    "\n",
    "다층 퍼셉트론에서 최적값을 찾아가는 과정은 오차 역전파 방법을 사용한다.\n",
    "\n",
    "\n",
    "<img src=\"인공신경망 (2).png\">\n",
    "\n",
    "입력층 -> 은닉층 -> 출력층 순서대로 흘러가는 것을 순전파(Forward Propagation)라고 하고, 반대로 역전파(Back Propagation)는 출력층 -> 은닉층 -> 입력층 순서대로 순전파의 경로를 거슬러 올라가는 방향이다.  \n",
    "오차 역전파를 기반으로 가중치와 편향값을 수정한 후 더 좋은 성능을 낼 수 있도록 모델을 개선한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b7ce2-0638-44d4-8f50-0baf918243e8",
   "metadata": {},
   "source": [
    "***\n",
    "활성화 함수(Activation Function)\n",
    "***\n",
    "활성화 함수는 딥러닝에서 입력값과 가중치 및 편향을 계산해서 해당 노드를 활성화 할지 결정하는 함수이다.  \n",
    "딥러닝에서 결과값을 결정하는 여러가지 활성화 함수가 존재한다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c02ff-787d-4e8f-ad14-3f0f9f7b2f07",
   "metadata": {},
   "source": [
    "- 항등 함수(Identity Fuction)\n",
    "    항등 함수 또는 선형 함수(Linear Fuction)라고도 부르는 이 함수는 입력과 출력이 같은 값을 가진다.  \n",
    "    주로 회귀 문제에서 출력층 활성화 함수로 사용한다.\n",
    "    \n",
    "    항등 함수는 아래의 식을 따른다. \n",
    "    \n",
    "    $$\\phi(x) = x$$\n",
    "    \n",
    "    부호 함수를 그림으로 나타내면 아래와 같다.  \n",
    "    <img src=\"./인공신경망 (9).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d46ff0-0120-4c8c-84c2-48391fae68be",
   "metadata": {},
   "source": [
    "\n",
    "- 계단(Step) 함수  \n",
    "    계단 함수는 아래의 식을 따른다.\n",
    "$$\\phi(x) = \n",
    "\\begin{cases}\n",
    "0, \\; x \\leq 0 \\\\\n",
    "1, \\; x > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "    계단 함수는 입력값이 0 이하일 경우 0을 출력하고, 0을 초과할 때만 1을 출력한다. 계단 함수의 출력은 0 또는 1로 오직 두가지 값만 가진다는 특징이 있다.\n",
    "    <img src=\"./인공신경망 (3).png\">  \n",
    "    \n",
    "    입력값 x가 0을 기준으로 0을 넘기전과 후의 값에 따라 출력값이 바뀌는 것을 알 수 있다.  \n",
    "    계단 함수는 사용하기 간단하다는 장점이 있지만 미분이 불가능하다는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8aaf63-550e-46b1-ae9c-cd619252d5f2",
   "metadata": {},
   "source": [
    "- 부호 함수(Sign Function)  \n",
    "    부호 함수는 아래의 식을 따른다.  \n",
    "    \n",
    "    $$\\phi(x) = \n",
    "    \\begin{cases}\n",
    "    1, \\; x > 0 \\\\\n",
    "    0, \\; x = 0 \\\\\n",
    "    -1, \\; x < 0\n",
    "    \\end{cases}$$\n",
    "    \n",
    "    부호 함수를 그림으로 나타내면 아래와 같다.   \n",
    "    \n",
    "    \n",
    "    <img src=\"./인공신경망 (4).png\">\n",
    "    \n",
    "    계단 함수와 비슷하게 생겼지만 0 또는 1만 출력하는 게단 함수와는 달리 -1, 0, 1 값을 출력하는 것을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408e1cf-c08d-44f4-b76d-c6f7b10dd6a1",
   "metadata": {},
   "source": [
    "- 시그모이드 함수(Sigmoid Fuction)  \n",
    "    시그모이드 함수는 아래와 같은 식을 따른다.  \n",
    "    \n",
    "    $$\\phi(x) = \\frac{1}{1 + e^{-x}}$$  \n",
    "    \n",
    "    시그모이드 함수를 그림으로 나타내면 아래와 같다.\n",
    "    \n",
    "    <img src=\"./인공신경망 (5).png\" >  \n",
    "    \n",
    "    시그모이드 함수는 0과 1사이의 값을 출력한다.  \n",
    "    시그모이드 함수를 딥러닝에 적용했을 때 단점은 학습하는 과정에서 미분을 반복하면 기울기 값이 매우 작아지는 기울기 소실(Vanishing Gradient) 문제가 발생할 수 있다.  \n",
    "    시그모이드 함수에서 x값이 지나치게 크거나 작을 경우, 미분값은 0에 가까워지고 이는 기울기 소실 문제를 발생시켜 학습 속도가 느려질 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e928fde-4af3-46f2-b565-7f44b26f7635",
   "metadata": {},
   "source": [
    "- 렐루 함수(Rectified Linear Function; Relu)  \n",
    "    렐루 함수는 다음과 같은 식을 따른다.  \n",
    "    \n",
    "    $$\\phi(x) = \n",
    "    \\begin{cases}\n",
    "    0, \\; x \\leq 0 \\\\\n",
    "    x, \\; x > 0\n",
    "    \\end{cases}$$\n",
    "    \n",
    "    위 식은 아래와 같이 한 줄로도 표현할 수 있다.  \n",
    "    \n",
    "$$\\phi(x) = max(x, 0)$$\n",
    "\n",
    "<img src=\"인공신경망 (7).png\">\n",
    "    \n",
    "    \n",
    "    렐루 함수는 x값이 0 이하라면 0을 출력하고, 양수면 x값을 출력한다.  \n",
    "    계산 함수, 부호 함수, 시그모이드 함수, 하이퍼볼릭 탄젠트 함수와는 달리 출력값의 상한선이 없다는 특징이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf24e83-11c1-4727-9cbd-c4f6b0127e11",
   "metadata": {},
   "source": [
    "- 리키 렐루 함수 (Leaky Relu Fuction)  \n",
    "    리키 렐루 함수는 다음과 같은 식을 따른다.  \n",
    "     $$\\phi(x) = \n",
    "    \\begin{cases}\n",
    "    ax, \\; x \\leq 0 \\\\\n",
    "    x, \\; x > 0\n",
    "    \\end{cases}$$\n",
    "    \n",
    "    위 함수에서 $a \\leq 1$이라면 아래와 같이 쓸 수 있다.  \n",
    "    \n",
    "    $$\\phi(x) = max(x, ax)$$  \n",
    "    \n",
    "    <img src=\"./인공신경망 (8).png\">\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cc210-7e7b-4af0-b119-52bd64fa7fd2",
   "metadata": {},
   "source": [
    "- 하이퍼볼릭 탄젠트 함수(Hyperbolic Tangent Function, tanh)  \n",
    "    하이퍼볼릭 탄젠트 함수는 다음과 같은 식을 따른다.  \n",
    "    \n",
    "    $$\\phi(x) = \\frac{exp(x) - exp(x)}{exp(x) + exp(x)}$$\n",
    "    \n",
    "    <img src=\"./인공신경망 (6).png\">  \n",
    "    \n",
    "    시그모이드 함수와 비슷하지만 시그모이드 함수 출력 범위는 0 -1 사이인 반면, 하이퍼볼릭 탄젠트 함수의 출력 범위는 -1 ~ 1 사이이다.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f75867-d9a9-4bf3-9c1a-73014191f5c4",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수(Softmax Fuction)  \n",
    "    소프트맥스 함수는 주로 최종 출력층에 사용되는 활성화 함수이다.  \n",
    "    만약, 해결해야할 문제가 회귀 문제라면 출력층에 항등 함수를 사용하고, 분류 문제일 경우에는 소프트맥스 함수를 사용한다.  \n",
    "    소프트맥스 함수는 아래와 같은 식을 따른다.  \n",
    "    \n",
    "    $$\\phi(x) = \\frac{exp(x_k)}{\\sum_{i=1}^n exp(x_i)}$$\n",
    "    \n",
    "    소프트맥스 함수를 사용할 때 위 식을 그대로 사용할 경우 오버플로우 문제가 발생할 수 있다.  \n",
    "    오버플로우는 출력값이 컴퓨터가 표현할 수 있는 수의 한계를 초과하면 생기는 문제를 말한다.  \n",
    "    예를 들어 $x_k = 1000$일 때, $exp(1000)$는 매우 큰 수가 되므로 계산하는 것이 불가능하다. 문제를 해결하기 위해 소프트맥스 함수를 아래와 같이 변경해서 사용하기도 한다.  \n",
    "    \n",
    "    $$\\phi(x) = \\frac{exp(x_k + C)}{\\sum_{i=1}^n exp(x_i + C)}$$\n",
    "    \n",
    "    소프트맥스 함수에서 지수연산을 할 때, 입력값에 임의의 상수 c를 더하거나 빼서 오버플로우 문제를 해결한다.  \n",
    "    임의의 상수 c는 일반적으로 입력값의 최대값을 이용한다.  \n",
    "    만약, 입력값이 999, 1000, 1001이라 할 때, 입력값의 최대값은 1001이므로 임의의 상수 C는 1001이 된다.  exp(999), exp(1000), exp(1001)를 구해야해서 오버플로우가 발생할 수 있지만, \n",
    "    입력값의 최대값을 빼주면 exp(-2), exp(-1), exp(0)와 같이 연산이 편해진다.  \n",
    "    \n",
    "    \n",
    "    <img src=\"인공신경망 (10).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f119d-1b7f-4911-8565-1876e7d645a2",
   "metadata": {},
   "source": [
    "***\n",
    "배치 정규화 (Batch Normalization)\n",
    "***\n",
    "배치 정규화는 해당층의 값의 분포를 변경하는 방법으로, 평균과 분산을 고정시키는 방법이다. 배치 정규화를 이용하면 기울기 소실을 줄일 수 있고, 신경망 학습 속도를 향상 시킬 수 있는 장점이 있다.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "드롭 아웃(DropOut)\n",
    "***\n",
    "신경망의 모든 노드를 사용하는 것이 아닌 일부 노드를 사용하는 방법  \n",
    "\n",
    "<img src=\"./인공신경망 (11).png\">\n",
    "\n",
    "왼쪽 그림은 드롭 아웃을 적용하기 전 신경망, 오른쪽 그림은 드롭아웃을 적용한 신경망이다.\n",
    "\n",
    "드롭아웃은 신경망에서 노드를 일시적으로 제거하는 방법이다.  어떤 노드를 신경망에서 제거할지는 각 계층에서 무작위로 선택된다.  \n",
    "드롭아웃을 적용하면 신경망의 노드 숫자가 줄어들고 이에 따라 연산량도 줄어들고 과대 적합을 방지 할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19dea5-c74d-4a4a-8dd9-6493d5a09d4b",
   "metadata": {},
   "source": [
    "***\n",
    "TensorFlow 2.x\n",
    "***\n",
    "TensorFlow는 파이썬을 이용, 딥러닝 학습시 사용하는 라이브러리이다.  \n",
    "TensorFlow를 활용하면 신경망을 기본으로 하는 딥러닝에서 다양한 신경망 관련 연산을 처리할 수 있어 편리하다.  \n",
    "\n",
    "tensorflow를 이용해 신경망 구조를 만드는 방법은 크게 시퀀스 API를 사용하는 방법과 함수형 API를 사용하는 방법이 있다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bed56c-fad1-4614-aa7b-68ff7677fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스를 사용하는 방법\n",
    "# Sequential 객체를 선언 후 Sequential 모델에 add() 메소드로 layer를 추가해서 쌓아올린다. \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential() # layer를 순차적으로 쌓아올리기 위한 Sequential 모델 객체를 만든다.\n",
    "\n",
    "# 입력 레이어는 input_shape 속성으로 입력 데이터 1건의 차원을 지정하고, \n",
    "# units 속성으로 다음 레이어로 전달되는 출력 차원,\n",
    "# activation 속성으로 활성화 함수를 지정해서 만든다.\n",
    "model.add(Dense(input_shape = (32, 32, 1), units = 100, activation = \"relu\") ) # 입력 레이어\n",
    "\n",
    "# 입력 레이어를 입력 데이터의 차원을 지정하는 input_shape 속성이 필요하지만, \n",
    "# 입력 레이어를 제외한 나머지 레이어는 이전 레이어의 출력이 현재 레이어의 입력으로 들어오기때문에 input_shape 속성이 필요없다. \n",
    "model.add(Dense(units = 50, activation = \"relu\")) # 히든 레이어\n",
    "\n",
    "model.add(Dense(units = 5, activation = \"softmax\")) # 출력 레이어\n",
    "\n",
    "# summary() 메소드로 만들어진 모델의 구조를 확인할 수 있다.\n",
    "model.summary()\n",
    "\n",
    "# Dense 레이어의 Param은 ((입력 차원;갯수 + 바이어스) x 출력 차원;갯수)으로 계산되고, 바이어스는 레이어당 1개이다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7670f1ed-4fea-40c0-9109-6b8f183c7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 함수를 사용하는 방법\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "\n",
    "# 입력 레이어\n",
    "input_layer = Input(shape=(32, 32, 1)) # 입력 데이터 1건의 차원을 지정\n",
    "#layer = Dense(units=100)(input_layer) # 입력 레이어을 만든다.\n",
    "#layer = Activation(\"relu\")(layer) # 입력 레이어의 활성화 함수를 지정한다.\n",
    "layer = Dense(units=100, activation = \"relu\")(input_layer)\n",
    "\n",
    "\n",
    "# 히든 레이어\n",
    "#layer = Dense(units=50)(layer) # 히든 레이어를 만든다.\n",
    "#layer = Activation(\"relu\")(layer) # 히든 레이어의 활성화 함수를 지정한다.\n",
    "layer = Dense(units=50, activation=\"relu\")(layer)\n",
    "\n",
    "# 출력 레이어\n",
    "#output_layer = Dense(units=5)(layer) # 출력 레이어를 만든다.\n",
    "#output_layer = Activation(\"softmax\")(output_layer) # 출력 레이어의 활성화 함수를 지정한다.\n",
    "output_layer = Dense(units=5, activation=\"softmax\")(layer)\n",
    "\n",
    "\n",
    "# Model 객체의 인수로 입력 데이터 1건의 차원과 출력 레이어를 넘겨서 모델을 생성한다.\n",
    "model = Model(input_layer, output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f5088d-a532-4287-8669-93db2d0c60b2",
   "metadata": {},
   "source": [
    "***\n",
    "모델 저장 및 불러오기\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ffa09b-7085-4d5c-90b7-074d4aaccd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장은 save() 메소드를 사용해서 \"h5\"파일로 저장한다. \n",
    "# \"h5\"는 \"hdf5\" 파일을 의미하고 Hierarchical Data Format Version 5 의 줄임말로 대용량 데이터를 저장하기 위한 파일 포맷이다.\n",
    "model.save(\"./model/ann_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4823a61c-9d31-4390-9f36-1d2771191749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# \"h5\"파일 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "ann_model = load_model(\"./model/ann_model.h5\")\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526cf2a-0794-4381-8740-acbba562e90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e485505-16eb-4714-ad2d-f0d9813c6487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925e915-9331-4622-bc09-94b05ee280b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d736f8-f9f0-45af-894b-a12b4d293f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4442c4-8719-414d-8ba6-fdc861083fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fa1a6-9774-42e5-b3b9-fc78ca583ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
